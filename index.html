<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation</title>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/Mathjax.js?config=AM_HTMLorMML-full"></script>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">  


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
     
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"> DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <!-- <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Hong Chen</a>,</span> -->
              <span class="author-block">
                Anonymous</span>
              <!-- <span class="author-block"> -->
                <!-- <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Yipeng Zhang</a></span> -->
                  </span>
                  </div>

                  <!-- <div class="is-size-5 publication-authors"> -->
                    <!-- <span class="author-block">Tsinghua University<br>Arxiv 2023</span> -->
                    <!--<span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>-->
                  <!-- </div> -->

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/disentangle.png" alt="result">
      <h2 class="subtitle has-text-centered">
        DisenBooth can disentangle the subject identity-relevant and the identity-irrelevant information in the given input images. Then DisenBooth utilizes the subject identity-relevant information, e.g., "a S* dog", and new text descriptions, e.g., "on top of a pink fabric", 
        to generate new images about the subject. The disentangled strategy tackles the problem of existing methods, where they overfit identity-irrelevant information or change the subject identity in the generated images.  
      </h2>
      <!-- <div class="content has-text-justified">
        <p>
          DisenBooth can disentangle the input images to a shared embedding and several image-specific embeddings, where the former is to capture the subject identity and the latter is used to capture the identity-unrelated information like background, pose, etc. The identity embedding can be used for better subject-driven text-to-image generation.
        </p>
      </div> -->
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Subject-driven text-to-image generation aims to generate customized images of the given subject based on the text descriptions, 
            which has drawn increasing attention recently. Existing methods mainly resort to finetuning a pretrained generative model, 
            where the identity-relevant information (e.g., the boy) and the identity-irrelevant information (e.g., the background or the pose of the boy) 
            are entangled in the latent embedding space. However, the highly entangled latent embedding may lead to the failure of subject-driven 
            text-to-image generation as follows: (i) the identity-irrelevant information hidden in the entangled embedding may dominate the generation process, 
            resulting in the generated images heavily dependent on the irrelevant information while ignoring the given text descriptions; 
            (ii) the identity-relevant information carried in the entangled embedding can not be appropriately preserved, resulting in 
            identity change of the subject in the generated images. To tackle the problems, we propose DisenBooth, an identity-preserving disentangled 
            tuning framework for subject-driven text-to-image generation in this paper. Specifically, DisenBooth finetunes the pretrained diffusion model 
            in the denoising process. Different from previous works that utilize an entangled embedding to denoise each image, DisenBooth instead utilizes 
            disentangled embeddings to respectively preserve the subject identity and capture the identity-irrelevant information. We further design 
            the novel weak denoising and contrastive embedding auxiliary tuning objectives to achieve the disentanglement. Extensive experiments 
            show that our proposed DisenBooth framework outperforms baseline models for subject-driven text-to-image generation with the identity-preserved embedding. 
            Additionally, by combining the identity-preserved embedding and identity-irrelevant embedding, DisenBooth demonstrates more generation flexibility and controllability.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Model Structure -->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Model Architecture</h2>
        <div class="hero-body">
          <div class="container">
            <img src="static/images/framework.png" alt="architecture">
          </div>
        </div>
        <div class="content has-text-justified">
          <p>
              DisenBooth conducts finetuning in the denoising process, where each input image is denoised with the textual embedding <math><msub><mi>f</mi><mn>s</mn></msub></math> shared by all the images to preserve the subject 
              identity, and visual embedding <math><msub><mi>f</mi><mn>i</mn></msub></math> to capture the identity-irrelevant information. To make the two embeddings disentangled, the weak 
              denoising objective <math><msub><mi>L</mi><mn>2</mn></msub></math> and the contrastive embedding objective <math><msub><mi>L</mi><mn>3</mn></msub></math> are proposed. Fine-tuned parameters include the adapter and the LoRA parameters.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Model Structures -->

<!-- Visual comparison with other methods-->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Visual Comparison to Other Methods</h2>
      </div>
    </div>
  </div>
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/dog_compare.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Generate different images of the same dog with different text prompts, given the input 5 images of the dog.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/can_comparison.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Generate different images of the same can with different text prompts, given the input 6 images of the can.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/complex1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Generating new images with more complex text prompts.
       </h2>
     </div>
  
    </div>
  </div>
</div>
</div>
</section>
<!-- End visual comparison with other methods-->


<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Animation Generation Results</h2>
        <div class="hero-body">
          <div class="container">
            <img src="static/images/anime_generation.png" alt="results">
          </div>
        </div>
        <div class="content has-text-justified">
          <p>
            We also use DisenBooth to finetune some anime characters, and DisenBooth can effectively generate animation pictures that preserve the subject identity and conform to the text descriptions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Model Structures -->


<!-- Disentanglement Result-->
<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Reference-Image-Guided Subject-Driven Text-to-Image Generation</h2>
        <div class="hero-body">
          <div class="container">
            <img src="static/images/ref_guided.png" alt="architecture">
          </div>
        </div>
        <div class="content has-text-justified">
          <p>
            With the disentangled identity-preserved and identity-irrelevant embeddings, we can jointly use the reference image and the text prompt to make the generated image conform to the text while inheriting some characteristics of the reference image.
            From left to right, we increase the weight of the image-irrelevant embedding, and the generated image will be more similar to the reference image while preserving the pose of the dog.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Disentanglement Result-->

<!-- Acknowledgement -->
<!-- <section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <p>
      The html template is from <a href="https://github.com/eliahuhorwitz/Academic-project-page-template">eliahuhorwitz/Academic-project-page-template</a>.
    </p>
  </div>
</section> -->

<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX"> -->
    <!-- <div class="container is-max-desktop content"> -->
      <!-- <h2 class="title">BibTeX</h2> -->
      <!-- <pre><code>BibTex Code Here</code></pre> -->
    <!-- </div> -->
<!-- </section> -->
<!--End BibTex citation -->


  <!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
